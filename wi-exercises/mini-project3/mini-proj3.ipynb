{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation\n",
    "We load the data, ignoring timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"ml-100k/u.data\", delimiter=\"\\t\", names=[\"userId\", \"itemId\", \"rating\", \"timestamp\"], usecols=[\"userId\", \"itemId\", \"rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dataframe[[\"userId\", \"itemId\"]]\n",
    "y = dataframe[\"rating\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning\n",
    "2a) Collaborative filtering fits the data best, as we do not have any content data. We only have information about the user and their ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtract the movie and user means from the training data (the pre-processing step from the slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.53014925373\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "movie_mean = train.groupby([\"itemId\"])[\"rating\"].mean()\n",
    "user_mean = train.groupby([\"userId\"])[\"rating\"].mean()\n",
    "avg_rating = train[\"rating\"].mean()\n",
    "# preprocess\n",
    "train[\"rating\"] = train.apply(lambda x: x.rating - movie_mean[x.itemId] - user_mean[x.userId] + avg_rating, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2c) Construct a matrix factorization CF model (a.k.a. “Funk-SVD”) for this training data. Use between 10 and 50 latent factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We want to find A, B such that R ~ AB\n",
    "def matrix_factorization(R, movie_count, user_count, K, learning_rate=0.001):\n",
    "    # shape(A) = len(movies), K\n",
    "    A = np.ones((movie_count + 1, K))\n",
    "    \n",
    "    # shape(B) = K, len(users)\n",
    "    B = np.ones((K, user_count + 1))\n",
    "    for x in range(0, 10000):\n",
    "        random_sample = R.sample(1)\n",
    "        sgd(random_sample, A, B, K, learning_rate)\n",
    "        \n",
    "    return (A, B)\n",
    "        \n",
    "def sgd(random_sample, A, B, K, learning_rate, weight_decay=0.647):\n",
    "    u = random_sample.userId.values[0]\n",
    "    m = random_sample.itemId.values[0]\n",
    "    Rmu = random_sample.rating.values[0]\n",
    "    \n",
    "    sum_count = 0\n",
    "    for i in range(0, K):\n",
    "        sum_count += A[m, i] * B[i, u]\n",
    "    \n",
    "    for k in range(0, K):\n",
    "        # update A\n",
    "        A[m, k] += learning_rate * (Rmu - sum_count) * B[k, u] - weight_decay * A[m, k]\n",
    "        # update B\n",
    "        B[k, u] += learning_rate * A[m, k] * (Rmu - sum_count) - weight_decay * B[k, u]\n",
    "\n",
    "max_movie_id = X[\"itemId\"].max()\n",
    "max_user_id = X[\"userId\"].max()\n",
    "A, B = matrix_factorization(train, max_movie_id, max_user_id, 40)\n",
    "\n",
    "model = np.dot(A, B)\n",
    "\n",
    "#Add the \"obvious\" structure back to the model\n",
    "for (movie,user), rating in np.ndenumerate(model):\n",
    "    movie_val = movie_mean.get(movie, default=0)\n",
    "    user_val = user_mean.get(user, default=0)\n",
    "    value = movie_val + user_val - avg_rating\n",
    "    model[movie, user] += value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d) This technique would scale good when data increases. The model can be calculated offline, and then updated periodically. The prediction is as simple as indexing a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring\n",
    "3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0507856518098091"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, user_id, movie_id):\n",
    "    return model[movie_id, user_id]\n",
    "predict(model, 196, 242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0928296327092968"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "y_pred = test.apply(lambda x: predict(model, x.userId, x.itemId), axis=1)\n",
    "\n",
    "\n",
    "MSE = mean_squared_error(y_true = y_test.values, y_pred = y_pred)\n",
    "MSE\n",
    "MSE**(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
